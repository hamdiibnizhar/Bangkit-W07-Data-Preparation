# -*- coding: utf-8 -*-
"""Bangkit #06-W07 - Data Preparation - Wine Quality

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XOp1e-R_KFpUBE7awda67ilLhQmJDcIJ

# Preparation
"""

#@title Import statements

import tensorflow as tf
import numpy as np
import pandas as pd
from tensorflow import keras
from tensorflow.keras import layers

print(tf.__version__)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import RFE
import ipython_genutils

#@title Import plotting functions

import matplotlib.pyplot as plt
import seaborn as sns
import pandas.util.testing as tm
from collections import Counter

#@title (Misc) GDrive integration
import os
from google.colab import drive
drive.mount('/content/gdrive')

"""# Feature Engineering

## Read dataset from CSV file
"""

url = 'https://raw.githubusercontent.com/hamdiibnizhar/bangkit-w05-winequality/master/datasets/winequality-red.csv'
df = pd.read_csv(url)

"""## Dataset characteristics and Imputation"""

df.head(10)
df.info()

"""Here we explore what our dataset has to offer."""

df['quality'].value_counts(sort=False)
sns.countplot(x='quality', data=df)

sns.pairplot(df)

def analizeSpreadData(originalData):
  mean = originalData.mean()
  median = originalData.median()
  mode = originalData.mode()[0]

  f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw= {"height_ratios": (3, 3)})
  sns.boxplot(originalData, ax=ax_box, color="y", width=10)
  ax_box.axvline(mean, color='r', linestyle='--')
  ax_box.axvline(median, color='g', linestyle='-')
  ax_box.axvline(mode, color='b', linestyle='-')

  sns.distplot(originalData, ax=ax_hist, hist=False, color="m", kde_kws={"shade": True})
  ax_box.axvline(mean, color='r', linestyle='--')
  ax_box.axvline(median, color='g', linestyle='-')
  ax_box.axvline(mode, color='b', linestyle='-')

  plt.legend({'Mean':mean,'Median':median,'Mode':mode})

  ax_box.set(xlabel='')
  plt.show()

for columns in df.columns:
  analizeSpreadData(df[columns])

"""## Handling Outlier
to 95%
"""

def outlierHandler(data):
  temp_df = pd.DataFrame()
  print("data before removing outlier :", data.shape)
  for column in data.columns:
    if column == 'quality':
      continue
    factor = 2
    upper_lim = data[column].mean () + data[column].std () * factor
    lower_lim = data[column].mean () - data[column].std () * factor
    
    # IQR = data[column].quantile(0.75) - data[column].quantile(0.25)
    # upper_lim = data[column].quantile(0.75) + 1.5*IQR
    # lower_lim = data[column].quantile(0.25) - 1.5*IQR

    temp_df = data[(data[column] < upper_lim) & (data[column] > lower_lim)]
  print("data after removing outlier :", temp_df.shape)
  return temp_df

df = outlierHandler(df)
sns.pairplot(df)

for columns in df.columns:
  analizeSpreadData(df[columns])

"""## Skewing and Binning"""

mean = df["quality"].mean()
median = df["quality"].median()
mode = df["quality"].mode()[0]

f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw= {"height_ratios": (0.2, 1)})

sns.boxplot(df["quality"], ax=ax_box, color="y", width=10)
ax_box.axvline(mean, color='r', linestyle='--')
ax_box.axvline(median, color='g', linestyle='-')
ax_box.axvline(mode, color='b', linestyle='-')

sns.distplot(df["quality"], ax=ax_hist, hist=False, color="m", kde_kws={"shade": True})
ax_hist.axvline(mean, color='r', linestyle='--')
ax_hist.axvline(median, color='g', linestyle='-')
ax_hist.axvline(mode, color='b', linestyle='-')

plt.legend({'Mean':mean,'Median':median,'Mode':mode})

ax_box.set(xlabel='')
plt.show()

df["quality"].skew()

"""## Group quality to 3 categories

Based on the spread of mean and median, to simplify our problem, we want to divide 0-10 quality scale into 3 rating categories: `low`, `moderate/average` and `high/good` quality. These categories should be more practical for real-world use.

We determine that:
- wine quality of `0 - 4` belongs to `low` rating (label: `0`)
- wine quality of `5 - 6` belongs to `moderate/average` rating (label: `1`)
- wine quality of `>= 7` belongs to `high/good` rating (label: `2`)
"""

# divide quality to rating
# 0 < q < 5: 0; 5 <= q < 7: 1; q >= 7: 2;

dataset = df.copy()
dataset['Rating'] = dataset['quality'].map(lambda x: 0 if x < 5 else 1 if x < 7 else 2)

dataset.pop("quality")
dataset['Rating'].value_counts()

"""# Feature Selection

## Pearson Correlation
"""

plt.figure(figsize=(12,10))
cor = dataset.corr()
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)
plt.show()

cor_target = abs(cor["Rating"])

#Selecting highly correlated features
relevant_features = cor_target[cor_target>0.13]
print(relevant_features)
selected_features1 = list(relevant_features.to_dict())
selected_features1

"""## Recursive Feature Elimination"""

X = dataset.copy()
Y = X.pop('Rating')
model = LinearRegression()

#Initializing RFE model
rfe = RFE(model, 7)

#Transforming data using RFE
X_rfe = rfe.fit_transform(X,Y)  

#Fitting the data to model
model.fit(X_rfe,Y)
print(rfe.support_)
print(rfe.ranking_)
rfe.support_

from sklearn.svm import SVC
from sklearn.svm import SVR
# model = SVC(gamma='auto')
model = SVR(kernel="linear")
rfe = RFE(model, 11)
#Transforming data using RFE
X_rfe = rfe.fit_transform(X,Y)  
#Fitting the data to model
model.fit(X_rfe,Y)
print(rfe.support_)
print(rfe.ranking_)

nof_list=np.arange(1,13)            
high_score=0
#Variable to store the optimum features
nof=0           
score_list =[]
for n in range(len(nof_list)):
    X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.3, random_state = 0)
    # model = LinearRegression()
    rfe = RFE(model,nof_list[n])
    X_train_rfe = rfe.fit_transform(X_train,y_train)
    X_test_rfe = rfe.transform(X_test)
    model.fit(X_train_rfe,y_train)
    score = model.score(X_test_rfe,y_test)
    score_list.append(score)
    if(score>high_score):
        high_score = score
        nof = nof_list[n]
print("Optimum number of features: %d" %nof)
print("Score with %d features: %f" % (nof, high_score))

cols = list(X.columns)

#Initializing RFE model
rfe = RFE(model, nof)             

#Transforming data using RFE
X_rfe = rfe.fit_transform(X,Y)  

#Fitting the data to model
model.fit(X_rfe,Y)              

temp = pd.Series(rfe.support_,index = cols)
selected_features_rfe = temp[temp==True].index
selected_features_rfe.sort_values()
# print(selected_features_rfe)
selected_features2 = selected_features_rfe.to_list()
selected_features2.append('Rating')

"""## Intersection List"""

def intersectionList(lists1, lists2):
  temp_list = []
  for list1 in lists1:
    for list2 in lists2:
      if list1 == list2:
        temp_list.append(list1)
  return temp_list

selected_features_intersect = intersectionList(selected_features1, selected_features2)
selected_features_intersect

selected_features_dataset = dataset[selected_features_intersect]

"""# Data Transformation

## Create test data

We don't have test data available as is from the source, so we have to create it from the data pool.

We decided to train on 80% of the data, and make the rest 20% as the test data.

To avoid bias, we divide the train and test data with random sampling.
"""

train_dataset = selected_features_dataset.sample(frac=0.8,random_state=0)
test_dataset = selected_features_dataset.drop(train_dataset.index)
train_dataset

"""Statistics of the training set.

We will use values from this stats (mean, std) to normalize the data.
"""

train_stats = train_dataset.describe()
train_stats.pop("Rating")
train_stats = train_stats.transpose()
train_stats

"""## Separate label and features"""

train_labels = train_dataset.pop('Rating')
test_labels = test_dataset.pop('Rating')

"""## Normalize values

On our attempt to see our dataset characteristics earlier, we see that range of the data varies.

For example, values of `fixed acidity` ranges from `4.6 - 15.9`, while `total sulfur dioxide` has a range of `6 - 62`. Meanwhile, `pH` values only range from `2.74` to `4.01`.

That this can cause  issues when training the model. Therefore, we convert each value of the features to its Z-score.
"""

#standardization
def z_score_norm(x):
  return (x - train_stats['mean']) / train_stats['std']

normed_train_data = z_score_norm(train_dataset)
normed_test_data = z_score_norm(test_dataset)

# show the boxplot to see the outlier
for columns in normed_train_data.columns:
  analizeSpreadData(normed_train_data[columns])

def lineGraphComparision(originalData, processedData):
  f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw= {"height_ratios": (3, 3)})
  sns.distplot(originalData, ax=ax_box, hist=False, color="y", kde_kws={"shade": True})
  sns.distplot(processedData, ax=ax_hist, hist=False, color="m", kde_kws={"shade": True})

def tableComparision(originalData, processedData, colName):
  temp_df = pd.DataFrame()
  newOriginalColName = colName + ' pre-scaling'
  newProcessedColName = colName +' post-scaling'
  temp_df[newOriginalColName] = originalData[colName].copy()
  temp_df[newProcessedColName] = processedData[colName].copy()
  display(temp_df.head(5))

normed_train_data.columns
for columns in normed_train_data.columns:
  lineGraphComparision(train_dataset[columns], normed_train_data[columns])
  tableComparision(train_dataset, normed_train_data, columns)

normed_train_data.describe().transpose()

"""# Define the function that builds model"""

def build_model(my_learning_rate):
  model = keras.Sequential([
    layers.Flatten(input_shape=[(len(train_dataset.keys()))]),
    layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    layers.Dense(3),
  ])

  optimizer = tf.keras.optimizers.Adam(learning_rate=my_learning_rate)

  model.compile(optimizer=optimizer,
              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
  return model

"""# Build and train the model"""

# Hyperparameters
EPOCHS = 200
learning_rate = 0.01

model = build_model(learning_rate)
print(model.summary())

checkpoint_path = "/content/gdrive/My Drive/Trained_Models/wine_binary_quality/wine_binary_quality.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)
history = model.fit(
  normed_train_data, train_labels,
  epochs=EPOCHS, 
  validation_split = 0.2, 
  # callbacks=[cp_callback],
  )

test_loss, test_acc = model.evaluate(
    normed_test_data, 
    test_labels, 
    verbose=2,
    )
print('Test accuracy:', test_acc)

"""# Evaluate the model"""

probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])
predictions = probability_model.predict(normed_test_data)

"""# Export model to GDrive"""

#Graph to look at the full set of 3 class predictions

def plot_value_array(i, predictions_array, true_label):
  predictions_array, true_label = predictions_array, true_label[i]
  plt.grid(False)
  plt.xticks(range(3))
  plt.yticks([])
  thisplot = plt.bar(range(3), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')

i = len(predictions)-2
array_test_labels = test_labels.to_numpy()

print("Real Value : ", array_test_labels[i])
print("Predicted Value : ", np.argmax(predictions[i]))
plot_value_array(i, predictions[i],  array_test_labels)

new_df = test_labels.copy()

new_df = new_df.reset_index()
del new_df["index"]
prediction_array = []

for prediction in predictions :
  prediction_array.append(np.argmax(prediction))
new_df["Rating Prediction"] = prediction_array
new_df.tail(20)

checkpoint_path = "/content/gdrive/My Drive/Trained_Models/wine_classifier/cp.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

model.save_weights('/content/gdrive/My Drive/Trained_Models/wine_classifier/wine_quality_model')

model_save_name = 'wine_classifier'
save_model_path = '/content/gdrive/My Drive/Trained_Models/wine_classifier'

model.save(save_model_path)

model.save('/content/gdrive/My Drive/Trained_Models/wine_classifier/wine_classifier.h5')

converter = tf.lite.TFLiteConverter.from_saved_model(save_model_path)
tflite_model = converter.convert()
open("/content/gdrive/My Drive/Trained_Models/wine_classifier/wine_classifier.tflite", "wb").write(tflite_model)